{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matched Filtering with PyCBC Inspiral\n",
    "\n",
    "**Duncan A. Brown<sup>1,2</sup>**\n",
    "\n",
    "**<sup>1</sup>Department of Physics, Syracuse University, Syracuse, NY 13244, USA**\n",
    "\n",
    "**<sup>2</sup>DARK, Niels Bohr Institute, University of Copenhagen, Blegdamsvej 17, 2100 Copenhagen, Denmark**\n",
    "\n",
    "This program is free software: you can redistribute it and/or modify it under the terms of the GNU General Public License as published by the Free Software Foundation, either version 3 of the License, or (at your option) any later version.\n",
    "\n",
    "This program is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU General Public License for more details.\n",
    "\n",
    "You should have received a copy of the GNU General Public License along with this program. If not, see http://www.gnu.org/licenses/.\n",
    "\n",
    "## Introduction\n",
    "\n",
    "This notebook demonstrates using the [``pycbc_inspiral``](https://raw.githubusercontent.com/ligo-cbc/pycbc/v1.7.5/bin/pycbc_inspiral) program to find the triggers from the LIGO Hanford and Livingston observatories corresponding to GW150914 event. This notebook uses the publically available [frame data from the LIGO Open Science Center (LOSC)](https://losc.ligo.org/events/GW150914/), input files from the [PyCBC Configuration GitHub repository](https://github.com/ligo-cbc/pycbc-config), and code from the [PyCBC GitHub repository.](https://github.com/ligo-cbc/pycbc)\n",
    "\n",
    "This notebook can be run from the PyCBC Docker container, or a machine with PyCBC installed. Instructions for [downloading the docker container](http://ligo-cbc.github.io/pycbc/latest/html/docker.html) are available from the [PyCBC home page.](https://ligo-cbc.github.io/) To start a container with instance of Jupyter notebook, run the commands\n",
    "```sh\n",
    "docker pull pycbc/pycbc-el7:v1.7.5\n",
    "docker run -p 8888:8888 --name pycbc_notebook -v -it pycbc/pycbc-el7:v1.7.5 /bin/bash -l\n",
    "```\n",
    "Once the container has started, this notebook can be downloaded with the command:\n",
    "```sh\n",
    "curl -L https://raw.githubusercontent.com/ligo-cbc/pycbc/master/examples/gw150914/PyCBCInspiral.ipynb > PyCBCInspiral.ipynb\n",
    "```\n",
    "The notebook server can be started inside the container with the command:\n",
    "```sh\n",
    "jupyter notebook --ip 0.0.0.0 --no-browser\n",
    "```\n",
    "You can then connect to the notebook at the URL printed by ``jupyter``.\n",
    "\n",
    "There are several (arbitrary) choices that can be made when constructing a matched filter for binary mergers, including the overall normalization of the signal-to-noise ratio, the reference time in the waveform for which the search reports the arrival time, and a scale factor to keep numerical quantites close to unity to prevent round-off error. Understanding these choices is essential for interpreting the reported time, phase, and amplitude needed to construct the best-fit waveform for a signal.\n",
    "\n",
    "``pycbc_inspiral`` used the FindChirp algorithm for matched filtering. For details of the choices made by the algorithm used here, see chapter 4 of [Duncan Brown's PhD thesis](https://arxiv.org/abs/0705.1514) and the [FindChirp paper in Phys Rev D.](https://journals.aps.org/prd/abstract/10.1103/PhysRevD.85.122006)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup notebook and download input data\n",
    "\n",
    "The following code sets up plotting and imports modules that we will use later in the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "% matplotlib inline\n",
    "% config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "from matplotlib import rcParams\n",
    "rcParams['figure.figsize']=(14,5)\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pycbc.types\n",
    "import pycbc.types.timeseries\n",
    "import pycbc.fft\n",
    "import pycbc.io.hdf\n",
    "import pycbc.waveform\n",
    "\n",
    "from pycbc import DYN_RANGE_FAC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the input frame data from LOSC\n",
    "\n",
    "The ``pycbc_inspiral`` code reads strain data from Frame format files. We download the calibrated frame data from the LIGO Open Science Center."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!if [ ! -f H-H1_LOSC_16_V2-1126257414-4096.gwf ] ; then curl https://losc.ligo.org/s/events/GW150914/H-H1_LOSC_16_V2-1126257414-4096.gwf > H-H1_LOSC_16_V2-1126257414-4096.gwf ; fi\n",
    "!if [ ! -f L-L1_LOSC_16_V2-1126257414-4096.gwf ] ; then curl https://losc.ligo.org/s/events/GW150914/L-L1_LOSC_16_V2-1126257414-4096.gwf > L-L1_LOSC_16_V2-1126257414-4096.gwf ; fi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the veto files\n",
    "\n",
    "These files are used to window out times when there are large delta function glitches in the input strain data that are identified by the Omicron burst search. This proceedure for identifying and removing these times from the search is described in the paper [GW150914: First results from the search for binary black hole coalescence with Advanced LIGO.](https://arxiv.org/abs/1602.03839)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!if [ ! -f H1-gating_C01_SNR300-1126051217-1129383017.txt.gz ] ; then curl -L https://raw.githubusercontent.com/ligo-cbc/pycbc-config/1e9aee13ebf85e916136afc4a9ae57f5b2d5bc64/O1/dq/H1-gating_C01_SNR300-1126051217-1129383017.txt.gz >  H1-gating_C01_SNR300-1126051217-1129383017.txt.gz ; fi\n",
    "!if [ ! -f L1-gating_C01_SNR300-1126051217-1129383017.txt.gz ] ; then curl -L https://raw.githubusercontent.com/ligo-cbc/pycbc-config/1e9aee13ebf85e916136afc4a9ae57f5b2d5bc64/O1/dq/L1-gating_C01_SNR300-1126051217-1129383017.txt.gz >  L1-gating_C01_SNR300-1126051217-1129383017.txt.gz ; fi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download a template bank containing the best-matching template for GW150914\n",
    "\n",
    "A bank of template parameters is needed as input to ``pycbc_inspiral``. The code will search over each template in the bank for a matching signal in the input strain data. The [full template bank](https://github.com/ligo-cbc/pycbc-config/blob/40a149012c6cc919b89342746dd9b31f894b20f5/O1/bank/README.md) used in the GW150914 search contains approximately 250,000 templates. Since we are only going to look at GW150914, we download a template bank containing only the template that best matches GW150915. This is the template indicated by a circle in Figure 1 of the paper [GW150914: First results from the search for binary black hole coalescence with Advanced LIGO.](https://arxiv.org/abs/1602.03839)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!if [ ! -f H1L1-GW150914_BANK-1126051217-3331800.xml ] ; then curl -L https://raw.githubusercontent.com/ligo-cbc/pycbc-config/master/O1/bank/H1L1-GW150914_BANK-1126051217-3331800.xml > H1L1-GW150914_BANK-1126051217-3331800.xml ;  fi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to use the template bank with the PyCBC trigger processing tools, we convert the XML format bank to HDF5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -f H1L1-GW150914_BANK-1126051217-3331800.hdf\n",
    "!pycbc_coinc_bank2hdf --verbose --bank-file H1L1-GW150914_BANK-1126051217-3331800.xml --output H1L1-GW150914_BANK-1126051217-3331800.hdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup pycbc_inspiral\n",
    "\n",
    "The following cells are based on downloading ``pycbc_inspiral`` from the [v1.7.5](https://github.com/ligo-cbc/pycbc/releases/tag/v1.7.5) release of PyCBC. The production GW150914 search used the [v1.3.2](https://github.com/ligo-cbc/pycbc/releases/tag/v1.3.2) release of PyCBC. PyCBC's Travis CI build and test suite ensures that the results of the code have not changed since this v1.3.2 release, when the code is run with the same parameters used to report the detection of GW150914 in the discovery PRL.\n",
    "\n",
    "### Code setup\n",
    "\n",
    "``pycbc_inspiral`` is a stand-alone program that is designed to be run from the command line. To run it within an IPython notebook, we first download it with the ``%load`` command. We then modify the code to place the main program in the function\n",
    "```python\n",
    "def findchirp(subtract_waveform=None):\n",
    "    # main pycbc_inspiral code goes here\n",
    "    \n",
    "    return [snr, norm, corr, idx, snrv], bank, segments, gwstrain\n",
    "```\n",
    "This allows us to run the code with the ``findchirp()`` function in this notebook and access the internal data structures of the code.\n",
    "\n",
    "The argument ``subtract_waveform`` allows us to pass a ``pycbc.types.TimeSeries`` that is subtracted from the strain data prior to filtering. To do this, we add the lines\n",
    "```python\n",
    "    if subtract_waveform:\n",
    "        logging.info('Removing waveform from input strain data')\n",
    "        gwstrain -= subtract_waveform\n",
    "```\n",
    "after reading in the ``gwstrain`` using ``strain.from_cli()``.\n",
    "\n",
    "Other than these modifications, the code is identical to the production filtering code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %load https://raw.githubusercontent.com/ligo-cbc/pycbc/v1.7.5/bin/pycbc_inspiral\n",
    "#!/usr/bin/env python\n",
    "\n",
    "# Copyright (C) 2014 Alex Nitz\n",
    "#\n",
    "# This program is free software; you can redistribute it and/or modify it\n",
    "# under the terms of the GNU General Public License as published by the\n",
    "# Free Software Foundation; either version 3 of the License, or (at your\n",
    "# option) any later version.\n",
    "#\n",
    "# This program is distributed in the hope that it will be useful, but\n",
    "# WITHOUT ANY WARRANTY; without even the implied warranty of\n",
    "# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU General\n",
    "# Public License for more details.\n",
    "#\n",
    "# You should have received a copy of the GNU General Public License along\n",
    "# with this program; if not, write to the Free Software Foundation, Inc.,\n",
    "# 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.\n",
    "\n",
    "import sys\n",
    "import logging, argparse, numpy, itertools\n",
    "import pycbc\n",
    "import pycbc.version\n",
    "from pycbc import vetoes, psd, waveform, strain, scheme, fft, DYN_RANGE_FAC, events\n",
    "from pycbc.vetoes.sgchisq import SingleDetSGChisq\n",
    "from pycbc.filter import MatchedFilterControl, make_frequency_series, qtransform\n",
    "from pycbc.types import TimeSeries, FrequencySeries, zeros, float32, complex64\n",
    "import pycbc.fft.fftw, pycbc.version\n",
    "import pycbc.opt\n",
    "import pycbc.weave\n",
    "import pycbc.inject\n",
    "import time\n",
    "\n",
    "last_progress_update = -1.0\n",
    "\n",
    "def update_progress(p,u,n):\n",
    "    \"\"\" updates a file 'progress.txt' with a value 0 .. 1.0 when enough (filtering) progress was made\n",
    "    \"\"\"\n",
    "    global last_progress_update\n",
    "    if p > last_progress_update + u:\n",
    "        f = open(n,\"w\")\n",
    "        if f:\n",
    "            f.write(\"%.4f\" % p)\n",
    "            f.close()\n",
    "        last_progress_update = p\n",
    "\n",
    "def findchirp(subtract_waveform=None):\n",
    "    global last_progress_update\n",
    "    \n",
    "    tstart = time.time()\n",
    "\n",
    "    parser = argparse.ArgumentParser(usage='',\n",
    "        description=\"Find single detector gravitational-wave triggers.\")\n",
    "\n",
    "    parser.add_argument('--version', action=pycbc.version.Version)\n",
    "    parser.add_argument(\"-V\", \"--verbose\", action=\"store_true\",\n",
    "                      help=\"print extra debugging information\", default=False )\n",
    "    parser.add_argument(\"--update-progress\",\n",
    "                      help=\"updates a file 'progress.txt' with a value 0 .. 1.0 when this amount of (filtering) progress was made\",\n",
    "                      type=float, default=0)\n",
    "    parser.add_argument(\"--update-progress-file\",\n",
    "                      help=\"name of the file to write the amount of (filtering) progress to\",\n",
    "                      type=str, default=\"progress.txt\")\n",
    "    parser.add_argument(\"--output\", type=str, help=\"FIXME: ADD\")\n",
    "    parser.add_argument(\"--bank-file\", type=str, help=\"FIXME: ADD\")\n",
    "    parser.add_argument(\"--snr-threshold\",\n",
    "                      help=\"SNR threshold for trigger generation\", type=float)\n",
    "    parser.add_argument(\"--newsnr-threshold\", type=float, metavar='THRESHOLD',\n",
    "                        help=\"Cut triggers with NewSNR less than THRESHOLD\")\n",
    "    parser.add_argument(\"--low-frequency-cutoff\", type=float,\n",
    "                      help=\"The low frequency cutoff to use for filtering (Hz)\")\n",
    "    parser.add_argument(\"--enable-bank-start-frequency\", action='store_true',\n",
    "                      help=\"Read the starting frequency of template waveforms\"\n",
    "                           \" from the template bank.\")\n",
    "    parser.add_argument(\"--max-template-length\", type=float,\n",
    "                      help=\"The maximum length of a template is seconds. The \"\n",
    "                           \"starting frequency of the template is modified to \"\n",
    "                           \"ensure the proper length\")\n",
    "    parser.add_argument(\"--enable-q-transform\", action='store_true',\n",
    "                      help=\"compute the q-transform for each segment of a \"\n",
    "                           \"given analysis run. (default = False)\")\n",
    "    # add approximant arg\n",
    "    pycbc.waveform.bank.add_approximant_arg(parser)\n",
    "    parser.add_argument(\"--order\", type=int,\n",
    "                      help=\"The integer half-PN order at which to generate\"\n",
    "                           \" the approximant. Default is -1 which indicates to use\"\n",
    "                           \" approximant defined default.\", default=-1,\n",
    "                           choices = numpy.arange(-1, 9, 1))\n",
    "    taper_choices = [\"start\",\"end\",\"startend\"]\n",
    "    parser.add_argument(\"--taper-template\", choices=taper_choices,\n",
    "                        help=\"For time-domain approximants, taper the start and/or\"\n",
    "                        \" end of the waveform before FFTing.\")\n",
    "    parser.add_argument(\"--cluster-method\", choices=[\"template\", \"window\"],\n",
    "                        help=\"FIXME: ADD\")\n",
    "    parser.add_argument(\"--cluster-function\", choices=[\"findchirp\", \"symmetric\"],\n",
    "                        help=\"How to cluster together triggers within a window. \"\n",
    "                        \"'findchirp' uses a forward sliding window; 'symmetric' \"\n",
    "                        \"will compare each window to the one before and after, keeping \"\n",
    "                        \"only a local maximum.\", default=\"findchirp\")\n",
    "    parser.add_argument(\"--cluster-window\", type=float, default = -1,\n",
    "                        help=\"Length of clustering window in seconds.\"\n",
    "                        \" Set to 0 to disable clustering.\")\n",
    "    parser.add_argument(\"--maximization-interval\", type=float, default=0,\n",
    "                        help=\"Maximize triggers over the template bank (ms)\")\n",
    "    parser.add_argument(\"--bank-veto-bank-file\", type=str, help=\"FIXME: ADD\")\n",
    "    parser.add_argument(\"--chisq-snr-threshold\", type=float,\n",
    "                        help=\"Minimum SNR to calculate the power chisq\")\n",
    "    parser.add_argument(\"--chisq-bins\", default=0, help=\n",
    "                        \"Number of frequency bins to use for power chisq. Specify\"\n",
    "                        \" an integer for a constant number of bins, or a function \"\n",
    "                        \"of template attributes.  Math functions are \"\n",
    "                        \"allowed, ex. \"\n",
    "                        \"'10./math.sqrt((params.mass1+params.mass2)/100.)'. \"\n",
    "                        \"Non-integer values will be rounded down.\")\n",
    "    parser.add_argument(\"--chisq-threshold\", type=float, default=0,\n",
    "                        help=\"FIXME: ADD\")\n",
    "    parser.add_argument(\"--chisq-delta\", type=float, default=0, help=\"FIXME: ADD\")\n",
    "    parser.add_argument(\"--autochi-number-points\", type=int, default=0,\n",
    "                        help=\"The number of points to use, in both directions if\"\n",
    "                             \"doing a two-sided auto-chisq, to calculate the\"\n",
    "                             \"auto-chisq statistic.\")\n",
    "    parser.add_argument(\"--autochi-stride\", type=int, default=0,\n",
    "                        help=\"The gap, in sample points, between the points at\"\n",
    "                             \"which to calculate auto-chisq.\")\n",
    "    parser.add_argument(\"--autochi-two-phase\", action=\"store_true\",\n",
    "                        default=False,\n",
    "                        help=\"If given auto-chisq will be calculated by testing \"\n",
    "                             \"against both phases of the SNR time-series. \"\n",
    "                             \"If not given, only the phase matching the trigger \"\n",
    "                             \"will be used.\")\n",
    "    parser.add_argument(\"--autochi-onesided\", action='store', default=None,\n",
    "                        choices=['left','right'],\n",
    "                        help=\"Decide whether to calculate auto-chisq using\"\n",
    "                             \"points on both sides of the trigger or only on one\"\n",
    "                             \"side. If not given points on both sides will be\"\n",
    "                             \"used. If given, with either 'left' or 'right',\"\n",
    "                             \"only points on that side (right = forward in time,\"\n",
    "                             \"left = back in time) will be used.\")\n",
    "    parser.add_argument(\"--autochi-reverse-template\", action=\"store_true\",\n",
    "                        default=False,\n",
    "                        help=\"If given, time-reverse the template before\"\n",
    "                             \"calculating the auto-chisq statistic. This will\"\n",
    "                             \"come at additional computational cost as the SNR\"\n",
    "                             \"time-series will need recomputing for the time-\"\n",
    "                             \"reversed template.\")\n",
    "    parser.add_argument(\"--autochi-max-valued\", action=\"store_true\",\n",
    "                        default=False,\n",
    "                        help=\"If given, store only the maximum value of the auto-\"\n",
    "                             \"chisq over all points tested. A disadvantage of this \"\n",
    "                             \"is that the mean value will not be known \"\n",
    "                             \"analytically.\")\n",
    "    parser.add_argument(\"--autochi-max-valued-dof\", action=\"store\", metavar=\"INT\",\n",
    "                        type=int,\n",
    "                        help=\"If using --autochi-max-valued this value denotes \"\n",
    "                             \"the pre-calculated mean value that will be stored \"\n",
    "                             \"as the auto-chisq degrees-of-freedom value.\")\n",
    "    parser.add_argument(\"--downsample-factor\", type=int,\n",
    "                        help=\"Factor that determines the interval between the \"\n",
    "                             \"initial SNR sampling. If not set (or 1) no sparse sample \"\n",
    "                             \"is created, and the standard full SNR is calculated.\", default=1)\n",
    "    parser.add_argument(\"--upsample-threshold\", type=float,\n",
    "                        help=\"The fraction of the SNR threshold to check the sparse SNR sample.\")\n",
    "    parser.add_argument(\"--upsample-method\", choices=[\"pruned_fft\"],\n",
    "                        help=\"The method to find the SNR points between the sparse SNR sample.\",\n",
    "                        default='pruned_fft')\n",
    "    parser.add_argument(\"--user-tag\", type=str, metavar=\"TAG\", help=\"\"\"\n",
    "                        This is used to identify FULL_DATA jobs for\n",
    "                        compatibility with pipedown post-processing.\n",
    "                        Option will be removed when no longer needed.\"\"\")\n",
    "    parser.add_argument(\"--keep-loudest-interval\", type=float,\n",
    "                        help=\"Window in seconds to maximize triggers over bank\")\n",
    "    parser.add_argument(\"--keep-loudest-num\", type=int,\n",
    "                        help=\"Number of triggers to keep from each maximization interval\")\n",
    "    parser.add_argument(\"--gpu-callback-method\", default='none')\n",
    "    parser.add_argument(\"--use-compressed-waveforms\", action=\"store_true\", default=False,\n",
    "                        help='Use compressed waveforms from the bank file.')\n",
    "    parser.add_argument(\"--waveform-decompression-method\", action='store', default=None,\n",
    "                        help='Method to be used decompress waveforms from the bank file.')\n",
    "\n",
    "    # Add options groups\n",
    "    psd.insert_psd_option_group(parser)\n",
    "    strain.insert_strain_option_group(parser)\n",
    "    strain.StrainSegments.insert_segment_option_group(parser)\n",
    "    scheme.insert_processing_option_group(parser)\n",
    "    fft.insert_fft_option_group(parser)\n",
    "    pycbc.opt.insert_optimization_option_group(parser)\n",
    "    pycbc.weave.insert_weave_option_group(parser)\n",
    "    pycbc.inject.insert_injfilterrejector_option_group(parser)\n",
    "    SingleDetSGChisq.insert_option_group(parser)\n",
    "    opt = parser.parse_args()\n",
    "\n",
    "    # Check that the values returned for the options make sense\n",
    "    psd.verify_psd_options(opt, parser)\n",
    "    strain.verify_strain_options(opt, parser)\n",
    "    strain.StrainSegments.verify_segment_options(opt, parser)\n",
    "    scheme.verify_processing_options(opt, parser)\n",
    "    fft.verify_fft_options(opt,parser)\n",
    "    pycbc.opt.verify_optimization_options(opt, parser)\n",
    "    pycbc.weave.verify_weave_options(opt, parser)\n",
    "\n",
    "    pycbc.init_logging(opt.verbose)\n",
    "\n",
    "    inj_filter_rejector = pycbc.inject.InjFilterRejector.from_cli(opt)\n",
    "    ctx = scheme.from_cli(opt)\n",
    "    gwstrain = strain.from_cli(opt, dyn_range_fac=DYN_RANGE_FAC,\n",
    "                               inj_filter_rejector=inj_filter_rejector)\n",
    "    \n",
    "    # Add code to subtract a waveform from the input time series\n",
    "    if subtract_waveform:\n",
    "        logging.info('Removing waveform from input strain data')\n",
    "        gwstrain -= subtract_waveform\n",
    "    \n",
    "    strain_segments = strain.StrainSegments.from_cli(opt, gwstrain)\n",
    "\n",
    "\n",
    "    with ctx:\n",
    "        fft.from_cli(opt)\n",
    "\n",
    "        flow = opt.low_frequency_cutoff\n",
    "        flen = strain_segments.freq_len\n",
    "        tlen = strain_segments.time_len\n",
    "        delta_f = strain_segments.delta_f\n",
    "\n",
    "\n",
    "        logging.info(\"Making frequency-domain data segments\")\n",
    "        segments = strain_segments.fourier_segments()\n",
    "        psd.associate_psds_to_segments(opt, segments, gwstrain, flen, delta_f,\n",
    "                      flow, dyn_range_factor=DYN_RANGE_FAC, precision='single')\n",
    "\n",
    "        # storage for values and types to be passed to event manager\n",
    "        out_types = {\n",
    "            'time_index'     : int,\n",
    "            'snr'            : complex64,\n",
    "            'chisq'          : float32,\n",
    "            'chisq_dof'      : int,\n",
    "            'bank_chisq'     : float32,\n",
    "            'bank_chisq_dof' : int,\n",
    "            'cont_chisq'     : float32,\n",
    "                    }\n",
    "        out_types.update(SingleDetSGChisq.returns)\n",
    "        out_vals = {key: None for key in out_types}\n",
    "        names = sorted(out_vals.keys())\n",
    "\n",
    "        if len(strain_segments.segment_slices) == 0:\n",
    "            logging.info(\"--filter-inj-only specified and no injections in analysis time\")\n",
    "            event_mgr = events.EventManager(\n",
    "                  opt, names, [out_types[n] for n in names], psd=None,\n",
    "                  gating_info=gwstrain.gating_info)\n",
    "            event_mgr.finalize_template_events()\n",
    "            event_mgr.write_events(opt.output)\n",
    "            logging.info(\"Finished\")\n",
    "            sys.exit(0)\n",
    "\n",
    "        if opt.enable_q_transform:\n",
    "            logging.info(\"Performing q-transform on analysis segments\")\n",
    "            q_trans = qtransform.inspiral_qtransform_generator(segments)\n",
    "\n",
    "        else:\n",
    "            q_trans = {}\n",
    "\n",
    "        # FIXME: Maybe we should use the PSD corresponding to each trigger\n",
    "        event_mgr = events.EventManager(\n",
    "                opt, names, [out_types[n] for n in names], psd=segments[0].psd,\n",
    "                gating_info=gwstrain.gating_info, q_trans=q_trans)\n",
    "\n",
    "        template_mem = zeros(tlen, dtype = complex64)\n",
    "        cluster_window = int(opt.cluster_window * gwstrain.sample_rate)\n",
    "\n",
    "        if opt.cluster_window == 0.0:\n",
    "            use_cluster = False\n",
    "        else:\n",
    "            use_cluster = True\n",
    "\n",
    "        if hasattr(ctx, \"num_threads\"):\n",
    "                ncores = ctx.num_threads\n",
    "        else:\n",
    "                ncores = 1\n",
    "\n",
    "\n",
    "        matched_filter = MatchedFilterControl(opt.low_frequency_cutoff, None,\n",
    "                                       opt.snr_threshold, tlen, delta_f, complex64,\n",
    "                                       segments, template_mem, use_cluster,\n",
    "                                       downsample_factor=opt.downsample_factor,\n",
    "                                       upsample_threshold=opt.upsample_threshold,\n",
    "                                       upsample_method=opt.upsample_method,\n",
    "                                       gpu_callback_method=opt.gpu_callback_method,\n",
    "                                       cluster_function=opt.cluster_function)\n",
    "\n",
    "        bank_chisq = vetoes.SingleDetBankVeto(opt.bank_veto_bank_file,\n",
    "                                              flen, delta_f, flow, complex64,\n",
    "                                              phase_order=opt.order,\n",
    "                                              approximant=opt.approximant)\n",
    "\n",
    "        power_chisq = vetoes.SingleDetPowerChisq(opt.chisq_bins, opt.chisq_snr_threshold)\n",
    "\n",
    "        autochisq = vetoes.SingleDetAutoChisq(opt.autochi_stride,\n",
    "                                     opt.autochi_number_points,\n",
    "                                     onesided=opt.autochi_onesided,\n",
    "                                     twophase=opt.autochi_two_phase,\n",
    "                                     reverse_template=opt.autochi_reverse_template,\n",
    "                                     take_maximum_value=opt.autochi_max_valued,\n",
    "                                     maximal_value_dof=opt.autochi_max_valued_dof)\n",
    "\n",
    "        logging.info(\"Overwhitening frequency-domain data segments\")\n",
    "        for seg in segments:\n",
    "            seg /= seg.psd\n",
    "\n",
    "        logging.info(\"Read in template bank\")\n",
    "        bank = waveform.FilterBank(opt.bank_file, flen, delta_f,\n",
    "            low_frequency_cutoff=None if opt.enable_bank_start_frequency else flow,\n",
    "            dtype=complex64, phase_order=opt.order,\n",
    "            taper=opt.taper_template, approximant=opt.approximant,\n",
    "            out=template_mem, max_template_length=opt.max_template_length,\n",
    "            enable_compressed_waveforms=True if opt.use_compressed_waveforms else False,\n",
    "            waveform_decompression_method=\n",
    "            opt.waveform_decompression_method if opt.use_compressed_waveforms else None)\n",
    "\n",
    "        sg_chisq = SingleDetSGChisq.from_cli(opt, bank, opt.chisq_bins)\n",
    "\n",
    "        ntemplates = len(bank)\n",
    "        nfilters = 0\n",
    "\n",
    "        logging.info(\"Full template bank size: %s\", ntemplates)\n",
    "        bank.template_thinning(inj_filter_rejector)\n",
    "        if not len(bank) == ntemplates:\n",
    "            logging.info(\"Template bank size after thinning: %s\", len(bank))\n",
    "\n",
    "        tsetup = time.time() - tstart\n",
    "\n",
    "        # Note: in the class-based approach used now, 'template' is not explicitly used\n",
    "        # within the loop.  Rather, the iteration simply fills the memory specifed in\n",
    "        # the 'template_mem' argument to MatchedFilterControl with the next template\n",
    "        # from the bank.\n",
    "        for t_num in xrange(len(bank)):\n",
    "            tmplt_generated = False\n",
    "\n",
    "            for s_num, stilde in enumerate(segments):\n",
    "                # Filter check checks the 'inj_filter_rejector' options to\n",
    "                # determine whether\n",
    "                # to filter this template/segment if injections are present.\n",
    "                if not inj_filter_rejector.template_segment_checker(\n",
    "                        bank, t_num, stilde, opt.gps_start_time):\n",
    "                    continue\n",
    "                if not tmplt_generated:\n",
    "                    template = bank[t_num]\n",
    "                    event_mgr.new_template(tmplt=template.params,\n",
    "                        sigmasq=template.sigmasq(segments[0].psd))\n",
    "                    tmplt_generated = True\n",
    "\n",
    "                if opt.cluster_method == \"window\":\n",
    "                    cluster_window = int(opt.cluster_window * gwstrain.sample_rate)\n",
    "                if opt.cluster_method == \"template\":\n",
    "                    cluster_window = \\\n",
    "                        int(template.chirp_length * gwstrain.sample_rate)\n",
    "\n",
    "                if opt.update_progress:\n",
    "                    update_progress((t_num + (s_num / float(len(segments))) ) / len(bank),\n",
    "                                    opt.update_progress, opt.update_progress_file)\n",
    "                logging.info(\"Filtering template %d/%d segment %d/%d\" %\n",
    "                             (t_num + 1, len(bank), s_num + 1, len(segments)))\n",
    "\n",
    "                nfilters = nfilters + 1\n",
    "                snr, norm, corr, idx, snrv = \\\n",
    "                   matched_filter.matched_filter_and_cluster(s_num,\n",
    "                                                             template.sigmasq(stilde.psd),\n",
    "                                                             cluster_window,\n",
    "                                                             epoch=stilde._epoch)\n",
    "\n",
    "                if not len(idx):\n",
    "                    continue\n",
    "\n",
    "                out_vals['bank_chisq'], out_vals['bank_chisq_dof'] = \\\n",
    "                      bank_chisq.values(template, stilde.psd, stilde, snrv, norm,\n",
    "                                        idx+stilde.analyze.start)\n",
    "\n",
    "                out_vals['chisq'], out_vals['chisq_dof'] = \\\n",
    "                      power_chisq.values(corr, snrv, norm, stilde.psd,\n",
    "                                         idx+stilde.analyze.start, template)\n",
    "\n",
    "                out_vals['sg_chisq'] = sg_chisq.values(stilde, template, stilde.psd,\n",
    "                                              snrv, norm,\n",
    "                                              out_vals['chisq'],\n",
    "                                              out_vals['chisq_dof'],\n",
    "                                              idx+stilde.analyze.start)\n",
    "\n",
    "                out_vals['cont_chisq'] = \\\n",
    "                      autochisq.values(snr, idx+stilde.analyze.start, template,\n",
    "                                       stilde.psd, norm, stilde=stilde,\n",
    "                                       low_frequency_cutoff=flow)\n",
    "\n",
    "                idx += stilde.cumulative_index\n",
    "\n",
    "                out_vals['time_index'] = idx\n",
    "                out_vals['snr'] = snrv * norm\n",
    "\n",
    "                event_mgr.add_template_events(names, [out_vals[n] for n in names])\n",
    "\n",
    "            event_mgr.cluster_template_events(\"time_index\", \"snr\", cluster_window)\n",
    "            event_mgr.finalize_template_events()\n",
    "\n",
    "    logging.info(\"Found %s triggers\" % str(len(event_mgr.events)))\n",
    "\n",
    "    if opt.chisq_threshold and opt.chisq_bins:\n",
    "        logging.info(\"Removing triggers with poor chisq\")\n",
    "        event_mgr.chisq_threshold(opt.chisq_threshold, opt.chisq_bins,\n",
    "                                  opt.chisq_delta)\n",
    "        logging.info(\"%d remaining triggers\" % len(event_mgr.events))\n",
    "\n",
    "    if opt.newsnr_threshold and opt.chisq_bins:\n",
    "        logging.info(\"Removing triggers with NewSNR below threshold\")\n",
    "        event_mgr.newsnr_threshold(opt.newsnr_threshold)\n",
    "        logging.info(\"%d remaining triggers\" % len(event_mgr.events))\n",
    "\n",
    "    if opt.keep_loudest_interval:\n",
    "        logging.info(\"Removing triggers that are not within the top %s loudest\"\n",
    "                     \" of a %s second interval\" % (opt.keep_loudest_num,\n",
    "                                                   opt.keep_loudest_interval))\n",
    "        event_mgr.keep_loudest_in_interval(opt.keep_loudest_interval * opt.sample_rate,\n",
    "                                           opt.keep_loudest_num)\n",
    "        logging.info(\"%d remaining triggers\" % len(event_mgr.events))\n",
    "\n",
    "    if opt.injection_window and hasattr(gwstrain, 'injections'):\n",
    "        logging.info(\"Keeping triggers within %s seconds of injection\" % opt.injection_window)\n",
    "        event_mgr.keep_near_injection(opt.injection_window, gwstrain.injections)\n",
    "        logging.info(\"%d remaining triggers\" % len(event_mgr.events))\n",
    "\n",
    "    if opt.maximization_interval:\n",
    "        logging.info(\"Maximizing triggers over %s ms window\" % opt.maximization_interval)\n",
    "        window = int(opt.maximization_interval * gwstrain.sample_rate / 1000)\n",
    "        event_mgr.maximize_over_bank(\"time_index\", \"snr\", window)\n",
    "        logging.info(\"%d remaining triggers\" % len(event_mgr.events))\n",
    "\n",
    "    tstop = time.time()\n",
    "    run_time = tstop - tstart\n",
    "    event_mgr.save_performance(ncores, nfilters, ntemplates, run_time, tsetup)\n",
    "\n",
    "    logging.info(\"Writing out triggers\")\n",
    "    event_mgr.write_events(opt.output)\n",
    "\n",
    "    if opt.fftw_output_float_wisdom_file:\n",
    "        fft.fftw.export_single_wisdom_to_filename(opt.fftw_output_float_wisdom_file)\n",
    "\n",
    "    if opt.fftw_output_double_wisdom_file:\n",
    "        fft.fftw.export_double_wisdom_to_filename(opt.fftw_output_double_wisdom_file)\n",
    "\n",
    "    logging.info(\"Finished\")\n",
    "    \n",
    "    return [snr, norm, corr, idx, snrv], bank, segments, gwstrain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the code\n",
    "\n",
    "To run the code, we first set up the command line arguments for ``pycbc_inspiral`` before calling the ``findchirp()`` function. The command line arguments below are taken from the [production analysis](https://sugwg-jobs.phy.syr.edu/~dbrown/gw150914/gw150914-16day-c01-v1.3.2/7._open_box_result/) for the GW150914 result. We first run the code for the LIGO Hanford detector, and then for the LIGO Livingston detector.\n",
    "\n",
    "The only difference between the command line arguments and the production arguments used in the discovery PRL are:\n",
    "\n",
    " 1. The template bank used is contains only the best-matching template for GW150914.\n",
    " 2. The ``--trig-start-time`` and ``--trig-end-time`` arguments that determine how much data will be searched for triggers are set to a 64 second interval centered the GPS time of GW150914 (1126259462).\n",
    " 3. We use the ``SEONBRv2`` time-domain template, rather than the ``SEOBNRv2_DoubleSpinROM`` frequency-domain template.\n",
    " 4. We start the filtering at 25 Hz, rather than 30 Hz to generate a slightly longer template."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up command line arguments common to both detectors\n",
    "\n",
    "The command line arguments below are common to running the code on both the Hanford and Livingston detector data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "argv = ['pycbc_inspiral', '--verbose']     \n",
    "argv += ['--approximant=SEOBNRv2', '--order=-1', '--taper-template=start']\n",
    "argv += ['--bank-file=H1L1-GW150914_BANK-1126051217-3331800.xml']\n",
    "argv += ['--pad-data=8', '--sample-rate=4096', '--strain-high-pass=20']\n",
    "argv += ['--segment-length=256', '--segment-start-pad=112', '--segment-end-pad=16']       \n",
    "argv += ['--psd-estimation=median', '--psd-segment-stride=8', '--psd-segment-length=16', '--psd-inverse-length=16']\n",
    "search_f_low = 25.0\n",
    "argv += ['--low-frequency-cutoff={}'.format(search_f_low)] \n",
    "argv += ['--trig-start-time=1126259430', '--trig-end-time=1126259494']\n",
    "argv += [\"--chisq-bins=0.4*get_freq('fSEOBNRv2Peak',params.mass1,params.mass2,params.spin1z,params.spin2z)**(2./3.)\"]\n",
    "argv += ['--snr-threshold=5.5', '--newsnr-threshold=5']   \n",
    "argv += ['--cluster-method=window', '--cluster-window=4', '--cluster-function=symmetric']\n",
    "argv += ['--injection-window=4.5', '--filter-inj-only']        \n",
    "argv += ['--processing-scheme=cpu']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the code for the Hanford detector\n",
    "\n",
    "We add the additional command line arguments that are specific to the Hanford detector and run the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "argv_h1_data = ['--frame-files=H-H1_LOSC_16_V2-1126257414-4096.gwf', '--channel-name=H1:LOSC-STRAIN',\n",
    "                '--gps-start-time=1126257636', '--gps-end-time=1126259684',\n",
    "                '--gating-file=H1-gating_C01_SNR300-1126051217-1129383017.txt.gz'\n",
    "               ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "argv_h1_out = ['--output=H1-INSPIRAL_FULL_DATA_JOB0-1126257771-1837.hdf', '--user-tag=FULL_DATA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "argv_h1 = argv + argv_h1_data + argv_h1_out\n",
    "sys.argv = argv_h1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -f H1-INSPIRAL_FULL_DATA_JOB0-1126257771-1837.hdf\n",
    "h1_result = findchirp()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Run the code for the Livingston detector\n",
    "\n",
    "We add the additional command line arguments that are specific to the Hanford detector and run the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "argv_l1_data = ['--frame-files=L-L1_LOSC_16_V2-1126257414-4096.gwf', '--channel-name=L1:LOSC-STRAIN',\n",
    "                '--gps-start-time=1126258108', '--gps-end-time=1126260156',\n",
    "                '--gating-file=L1-gating_C01_SNR300-1126051217-1129383017.txt.gz'\n",
    "               ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "argv_l1_out = ['--output=L1-INSPIRAL_FULL_DATA_JOB0-1126258302-1591.hdf', '--user-tag=FULL_DATA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "argv_l1 = argv + argv_l1_data + argv_l1_out\n",
    "sys.argv = argv_l1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -f L1-INSPIRAL_FULL_DATA_JOB0-1126258302-1591.hdf\n",
    "l1_result = findchirp()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process the results\n",
    "\n",
    "### Read triggers from the output files\n",
    "\n",
    "The ``pycbc_inspiral`` code writes its output to the HDF5 files specified by the ``--output`` argument. We read in these files and find the triggers with the largest signal-to-noise ratio, as these correspond to those from GW150914."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h1_triggers = pycbc.io.hdf.SingleDetTriggers(\n",
    "    'H1-INSPIRAL_FULL_DATA_JOB0-1126257771-1837.hdf',\n",
    "    'H1L1-GW150914_BANK-1126051217-3331800.hdf',\n",
    "    None, None, None, 'H1'\n",
    ")\n",
    "\n",
    "l1_triggers = pycbc.io.hdf.SingleDetTriggers(\n",
    "    'L1-INSPIRAL_FULL_DATA_JOB0-1126258302-1591.hdf',\n",
    "    'H1L1-GW150914_BANK-1126051217-3331800.hdf',\n",
    "    None, None, None, 'L1'\n",
    ")\n",
    "\n",
    "imax = np.argmax(h1_triggers.snr)\n",
    "t_h1 = h1_triggers.end_time[imax]\n",
    "t_idx_h1 = h1_result[0][3][np.argmax(np.abs(h1_result[0][4]))]\n",
    "snr_h1 = h1_triggers.snr[imax]\n",
    "sigmasq = h1_triggers.get_column('sigmasq')[0]\n",
    "eff_distance_h1 = (sigmasq)**0.5 / snr_h1\n",
    "\n",
    "imax = np.argmax(l1_triggers.snr)\n",
    "t_l1 = l1_triggers.end_time[imax]\n",
    "t_idx_l1 = l1_result[0][3][np.argmax(np.abs(l1_result[0][4]))]\n",
    "snr_l1 = l1_triggers.snr[imax]\n",
    "sigmasq = l1_triggers.get_column('sigmasq')[0]\n",
    "eff_distance_l1 = (sigmasq)**0.5 / snr_l1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print the parameters of the GW150914 triggers\n",
    "\n",
    "We print the arrival time, signal-to-noise ratio, and time delay for the H1 and L1 triggers. We also print the effective distance measured by the search code, as this is needed to scale the *amplitude* of the best-fit template.\n",
    "\n",
    "``pycbc_inspiral`` records the sample index of the trigger, relative to the start of the strain time series that is read in. We save this arrival time offset as it will be used later to set the *arrival time* of the best-fit template."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print \"H1 Time of event is {} with signal-to-noise ratio {}\".format(t_h1, snr_h1)\n",
    "print \"L1 Time of event is {} with signal-to-noise ratio {}\".format(t_l1, snr_l1)\n",
    "print \"HL arrival time difference = {} ms\".format(t_h1-t_l1)\n",
    "print \"H1 Effective distance = {} Mpc, L1 effective distance = {} Mpc\".format(eff_distance_h1, eff_distance_l1)\n",
    "print \"H1 arrival time offset = {}, L1 arrival time offset = {}\".format(t_idx_h1,t_idx_l1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the SNR time series for the two detectors\n",
    "\n",
    "Now we plot the signal-to-noise ratio time series for each detector. The filtering function used by ``pycbc_inspiral`` generates the complex signal-to-noise ratio time series. In our code, this is returned in the array `` h1_result[0][0].data``. The complex signal-to-noise ratio is scaled by a normalization factor stored in ``h1_result[0][1]``. We plot the absolute value of the complex signal-to-noise, relative to GPS time 1126259462. For comparison, we draw vertical lines at the time of the GW150914 trigger. It can be seen that the signal-to-noise ratio time series peaks at the time of the trigger, as expected. We also store the array index of this peak, as we will use this to compute the phase of the best-fit template."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h1_complex_snr = h1_result[0][0].data*h1_result[0][1]\n",
    "h1_snr_data = np.abs(h1_complex_snr)\n",
    "h1_snr_t = h1_result[0][0].sample_times - 1126259462\n",
    "h1_imax = np.argmax(h1_snr_data)\n",
    "\n",
    "l1_complex_snr = l1_result[0][0].data*l1_result[0][1]\n",
    "l1_snr_data = np.abs(l1_complex_snr)\n",
    "l1_snr_t = l1_result[0][0].sample_times - 1126259462\n",
    "l1_imax = np.argmax(l1_snr_data)\n",
    "\n",
    "plt.plot(h1_snr_t,h1_snr_data,color='r',label=\"H1\")\n",
    "plt.axvline(t_h1-1126259462,color='r',linestyle=':')\n",
    "\n",
    "plt.plot(l1_snr_t,l1_snr_data,color='g',label=\"L1\")\n",
    "plt.axvline(t_l1-1126259462,color='g',linestyle=':')\n",
    "\n",
    "plt.legend(loc='best')\n",
    "plt.xlim([0.3,0.5])\n",
    "plt.ylim([0,20])\n",
    "plt.xlabel(\"Time from 1126259462 (seconds)\")\n",
    "plt.ylabel(\"Signal-to-noise ratio\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute the phase of the best fit template\n",
    "\n",
    "We use the peak index and the complex signal-to-noise ratio to compute the *coalescence phase* of the best-fit template."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phase_h1 = np.arctan2(h1_complex_snr[h1_imax].imag,h1_complex_snr[h1_imax].real)\n",
    "phase_l1 = np.arctan2(l1_complex_snr[l1_imax].imag,l1_complex_snr[l1_imax].real)\n",
    "\n",
    "print \"H1 Coalescence phase = {} radians, L1 Coalescence phase = {} radians\".format(phase_h1,phase_l1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the template used in the bank\n",
    "\n",
    "For visual comparison, we plot the template used in the search compared to an ``SEOBNRv2`` waveform directly generated with the template parameters. ``pycbc_inspiral`` stores templates in the frequency domain, so we convert the template to the time domain for plotting with the command:\n",
    "```python\n",
    "template = h1_bank[0].to_timeseries()\n",
    "```\n",
    "The waveforms are computed for a signal at a distance of 1 Mpc. ``pycbc_inspiral`` applies an internal scaling of approximately 6e20 to scale these quanties up to order unity (the exact scaling is stored in the constant ``pycbc.DYN_RANGE_FAC``). We divide the amplitude of the template by ``DYN_RANGE_FAC`` so that it has the correct amplitude.\n",
    "\n",
    "The FindChirp algorithm expects the peak time of the template to be at ``t = 0`` in the time domain so that the signal-to-noise ratio time series is time-stamped reference to the peak (coalescence) time of the waveform. Since the FFT is periodic, this means that the signal prior to the merger is at the *end* of the time-domain template and the merger-ringdown waveform is at the *start* of the time-domain template. We use NumPy's ``roll`` function to shift the sample points of the template so that it is contiguous and can be plotted against the result of calling ``pycbc.waveform.get_td_waveform()`` to generate the SEOBNRv2 waveform.\n",
    "\n",
    "Notice that the only difference between the template waveform and the reference SEOBNRv2 waveform is that the search template is windowed at the start to prevent Gibbs ringing when it is transformed into the frequency domain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "h1_bank = h1_result[1]\n",
    "l1_bank = l1_result[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hp, hc = pycbc.waveform.get_td_waveform(\n",
    "    approximant=\"SEOBNRv2\",\n",
    "    mass1=h1_bank.table['mass1'][0],\n",
    "    mass2=h1_bank.table['mass2'][0],\n",
    "    spin1z=h1_bank.table['spin1z'][0],\n",
    "    spin2z=h1_bank.table['spin2z'][0],\n",
    "    f_lower=search_f_low,\n",
    "    delta_t=h1_bank.delta_t)\n",
    "\n",
    "template = h1_bank[0].to_timeseries()\n",
    "\n",
    "plt.plot(template.sample_times,\n",
    "         np.roll(template,int(np.floor(-1.0*min(template.sample_times)/template.delta_t)))/DYN_RANGE_FAC,\n",
    "         color='r',label='Search template')\n",
    "plt.plot(hp.sample_times, hp,linestyle=':',label='SEOBNRv2')\n",
    "\n",
    "plt.xlim([-0.3,0.05])\n",
    "plt.title('Search template at 1 Mpc')\n",
    "plt.legend(loc='best')\n",
    "plt.ylabel('Strain'.format(DYN_RANGE_FAC))\n",
    "plt.xlabel('Time from waveform peak (seconds)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate the best fit template\n",
    "\n",
    "To generate the best-fit template, we must take the template above and apply the approriate time, phase, and amplitude shifts reported by the search code.\n",
    "\n",
    "### Create storage for the template.\n",
    "\n",
    "We generate an empty ``pycbc.types.TimeSeries`` for each template."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "h1_best_fit_waveform = pycbc.types.TimeSeries(\n",
    "    pycbc.types.Array(np.zeros(h1_bank.N),dtype=np.float32),\n",
    "    delta_t=h1_bank.delta_t)\n",
    "\n",
    "l1_best_fit_waveform = pycbc.types.TimeSeries(\n",
    "    pycbc.types.Array(np.zeros(l1_bank.N),dtype=np.float32),\n",
    "    delta_t=l1_bank.delta_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the time-domain template\n",
    "\n",
    "We apply the correct phase shift measured by the search code to the frequency-domain template and then inverse Fourier transform the search template into the time domain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pycbc.fft.ifft(h1_bank[0]*np.exp(1j*phase_h1),h1_best_fit_waveform)\n",
    "pycbc.fft.ifft(l1_bank[0]*np.exp(-1j*(phase_l1)),l1_best_fit_waveform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create storage for template subtraction\n",
    "\n",
    "We create an array containing zeros that is the same length and sample rate as the input strain time series. This is needed to subtract the best-fit template prior to filtering the data in ``pycbc_inspiral``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "h1_strain = h1_result[3]\n",
    "l1_strain = l1_result[3]\n",
    "\n",
    "h1_remove = pycbc.types.timeseries.TimeSeries(pycbc.types.Array(np.zeros(len(h1_strain))),\n",
    "                                   delta_t=h1_strain.delta_t,\n",
    "                                   dtype=np.float32, epoch=h1_strain.start_time)\n",
    "\n",
    "l1_remove = pycbc.types.timeseries.TimeSeries(pycbc.types.Array(np.zeros(len(l1_strain))),\n",
    "                                   delta_t=l1_strain.delta_t,\n",
    "                                   dtype=np.float32, epoch=l1_strain.start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Place the template in the time series\n",
    "\n",
    "Using the measured arrival index and amplitude scaling, we place the template at the correct location in the time series created in the previous cell.\n",
    "\n",
    "When this cell is evaluated, the time series ``h1_remove`` and ``l1_remove`` will contain the correctly time, phase, and amplitude shifted waveform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(h1_best_fit_waveform)/2):\n",
    "    h1_remove.data[t_idx_h1+i] = h1_best_fit_waveform[i] / eff_distance_h1\n",
    "    \n",
    "for i in range(len(h1_best_fit_waveform)/2):\n",
    "    h1_remove.data[t_idx_h1-(len(h1_best_fit_waveform)/2)+i] = h1_best_fit_waveform[i+len(h1_best_fit_waveform)/2] / eff_distance_h1\n",
    "\n",
    "for i in range(len(l1_best_fit_waveform)/2):\n",
    "    l1_remove.data[t_idx_l1+i] = l1_best_fit_waveform[i] / eff_distance_l1\n",
    "    \n",
    "for i in range(len(l1_best_fit_waveform)/2):\n",
    "    l1_remove.data[t_idx_l1-(len(l1_best_fit_waveform)/2)+i] = l1_best_fit_waveform[i+len(l1_best_fit_waveform)/2] / eff_distance_l1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare the best-fit waveform to the NR data\n",
    "\n",
    "We now compare the best-fit template to the raw numerical relavity data shown in Figure 2 of the PRL, and the filtered NR waveform shown Figure 1 of the PRL.\n",
    "\n",
    "### Load NR data from Figure 1\n",
    "\n",
    "The LOSC NR data is scalled by a factor of 1e21. We undo this scaling when we plot the data for comparison to the best-fit waveform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!if [ ! -f fig2-unfiltered-waveform-H.txt ] ; then curl -L \"https://losc.ligo.org/s/events/GW150914/P150914/fig2-unfiltered-waveform-H.txt\" > fig2-unfiltered-waveform-H.txt ; fi\n",
    "!if [ ! -f fig2-unfiltered-waveform-L.txt ] ; then curl -L \"https://losc.ligo.org/s/events/GW150914/P150914/fig2-unfiltered-waveform-L.txt\" > fig2-unfiltered-waveform-L.txt ; fi\n",
    "!if [ ! -f fig1-waveform-H.txt ] ; then curl -L \"https://losc.ligo.org/s/events/GW150914/P150914/fig1-waveform-H.txt\" > fig1-waveform-H.txt ; fi\n",
    "!if [ ! -f fig1-waveform-L.txt ] ; then curl -L \"https://losc.ligo.org/s/events/GW150914/P150914/fig1-waveform-L.txt\" > fig1-waveform-L.txt ; fi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nr_filt_data = np.loadtxt(\"fig1-waveform-H.txt\")\n",
    "dt=nr_filt_data[1,0]-nr_filt_data[0,0]\n",
    "h1_nr_filt_hp = pycbc.types.TimeSeries(nr_filt_data[:,1],delta_t=dt,epoch=nr_filt_data[0,0])\n",
    "\n",
    "nr_data = np.loadtxt(\"fig2-unfiltered-waveform-H.txt\")\n",
    "dt=nr_data[1,0]-nr_data[0,0]\n",
    "h1_nr_hp = pycbc.types.TimeSeries(nr_data[:,1],delta_t=dt,epoch=nr_data[0,0])\n",
    "\n",
    "nr_filt_data = np.loadtxt(\"fig1-waveform-L.txt\")\n",
    "dt=nr_filt_data[1,0]-nr_filt_data[0,0]\n",
    "l1_nr_filt_hp = pycbc.types.TimeSeries(nr_filt_data[:,1],delta_t=dt,epoch=nr_filt_data[0,0])\n",
    "\n",
    "nr_data = np.loadtxt(\"fig2-unfiltered-waveform-L.txt\")\n",
    "dt=nr_data[1,0]-nr_data[0,0]\n",
    "l1_nr_hp = pycbc.types.TimeSeries(nr_data[:,1],delta_t=dt,epoch=nr_data[0,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Trim the best fit waveform\n",
    "\n",
    "For faster plotting, we trim the full ``h1_remove`` and ``l1_remove`` time series to an interval of 2 seconds before and 2 seconds after GPS time 1126259462."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "h1_bf = h1_remove.time_slice(1126259462-2,1126259462+2)\n",
    "l1_bf = l1_remove.time_slice(1126259462-2,1126259462+2)\n",
    "\n",
    "h1_bf.save('H1BestFitTemplate.txt')\n",
    "l1_bf.save('L1BestFitTemplate.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare the best-fit waveform to the Fig 1 data\n",
    "\n",
    "We plot the best-fit waveform from the search and compare it to the data from Figure 1 of the PRL. The L1 raw NR waveform is shifted by 0.007 s and multiplied by -1, as described in the caption of Figure 1.\n",
    "\n",
    "Notice that in both of these plots there is a phase shift between the *raw NR waveform* and the *filtered NR waveform*. This is beacuse the filters used in Figure 1 of the PRL are not phase preserving."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(h1_nr_filt_hp.sample_times, h1_nr_filt_hp*1e-21,\n",
    "         color='b', label='Fig 1 NR waveform',linestyle=':')\n",
    "plt.plot(h1_nr_hp.sample_times, h1_nr_hp*1e-21 ,color='g', label='SXS:BBH:0305')\n",
    "plt.plot(h1_bf.sample_times-1126259462, h1_bf/DYN_RANGE_FAC, color='r', label='Best fit template')\n",
    "\n",
    "plt.xlim([0.3,0.45])\n",
    "plt.ylim([-1.4e-21,1.4e-21])\n",
    "plt.title('LIGO Hanford Detector')\n",
    "plt.legend(loc='best')\n",
    "plt.ylabel('Strain $\\\\times$ {0:.1e}'.format(DYN_RANGE_FAC))\n",
    "plt.xlabel('Time from 1126259462 (seconds)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(l1_nr_filt_hp.sample_times, l1_nr_filt_hp*1e-21,\n",
    "         color='b', label='Fig 1 NR waveform',linestyle=':')\n",
    "plt.plot(l1_nr_hp.sample_times-0.007, l1_nr_hp*-1e-21, color='g', label='SXS:BBH:0305')\n",
    "plt.plot(l1_bf.sample_times-1126259462, l1_bf/DYN_RANGE_FAC, color='r', label='Best fit template')\n",
    "\n",
    "plt.xlim([0.3,0.45])\n",
    "plt.ylim([-1.4e-21,1.4e-21])\n",
    "plt.title('LIGO Livingston Detector')\n",
    "plt.legend(loc='best')\n",
    "plt.ylabel('Strain')\n",
    "plt.xlabel('Time from 1126259462 (seconds)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Filter the data with the best-fit waveform subtracted\n",
    "\n",
    "We now re-run ``pycbc_inspiral`` but this time we pass the best-fit waveform to the ``findchip()`` function so that it is removed from the data prior to the matched filter.\n",
    "\n",
    "Since we have removed the GW150914 signal, the search code should not find any triggers. In the case where no triggers are found ``pycbc_inspiral``'s filtering function does not return any data. To force the code to return the signal-to-noise ratio time series, we set the SNR and newSNR thresholds to unity before running it.\n",
    "\n",
    "### Hanford detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.argv = [a for a in argv_h1 if not (a.startswith('--snr-threshold') or a.startswith('--newsnr-threshold'))]\n",
    "sys.argv += ['--snr-threshold=1', '--newsnr-threshold=1']\n",
    "\n",
    "!rm -f H1-INSPIRAL_FULL_DATA_JOB0-1126257771-1837.hdf\n",
    "h1_null_result = findchirp(h1_remove)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Livingston detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.argv = [a for a in argv_l1 if not (a.startswith('--snr-threshold') or a.startswith('--newsnr-threshold'))]\n",
    "sys.argv += ['--snr-threshold=1', '--newsnr-threshold=1']\n",
    "\n",
    "!rm -f L1-INSPIRAL_FULL_DATA_JOB0-1126258302-1591.hdf\n",
    "l1_null_result = findchirp(l1_remove)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the signal-to-noise ratio time series\n",
    "\n",
    "Now we plot the signal-to-noise ratio time series returned by the search for each detector, with vertial lines indicating the trigger times of GW150914.\n",
    "\n",
    "Notice that there is no trigger corresponding to GW150914 in the output and the values of the SNR at the time of the GW150914 are consistent with noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h1_complex_snr = h1_null_result[0][0].data*h1_null_result[0][1]\n",
    "h1_snr_data = np.abs(h1_complex_snr)\n",
    "h1_snr_t = h1_null_result[0][0].sample_times - 1126259462\n",
    "\n",
    "l1_complex_snr = l1_null_result[0][0].data*l1_null_result[0][1]\n",
    "l1_snr_data = np.abs(l1_complex_snr)\n",
    "l1_snr_t = l1_null_result[0][0].sample_times - 1126259462\n",
    "\n",
    "plt.plot(h1_snr_t,h1_snr_data,color='r',label=\"H1\")\n",
    "plt.axvline(t_h1-1126259462,color='r',linestyle=':')\n",
    "\n",
    "plt.plot(l1_snr_t,l1_snr_data,color='g',label=\"L1\")\n",
    "plt.axvline(t_l1-1126259462,color='g',linestyle=':')\n",
    "\n",
    "plt.legend(loc='best')\n",
    "plt.xlim([0.3,0.5])\n",
    "plt.ylim([0,4])\n",
    "plt.xlabel(\"Time from 1126259462 (seconds)\")\n",
    "plt.ylabel(\"Signal-to-noise ratio\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the whitened strain data\n",
    "\n",
    "The matched filter in ``pycbc_inspiral`` stores the [overwhitened strain data](https://github.com/ligo-cbc/pycbc/blob/v1.7.5/bin/pycbc_inspiral#L294). Data is overwhitened in the frequency domain by dividing by the time-truncated inverse power spectral density of the data, as described in the the [FindChirp algorithm.](https://journals.aps.org/prd/abstract/10.1103/PhysRevD.85.122006) To plot the whitened strain, we multiply the frequency-domain overwhitened data by the square root of the power spectral density used to overwhiten it, then use PyCBC's ``to_timeseries()`` function to transform back to the time domain.\n",
    "\n",
    "**Note:** this whitened strain is not used by any downstream product and it is not normally constructed by ``pycbc_inspiral``. It is just used here to plot whitened strain data for visualization of the results of this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "whitened_strain_h1 = (h1_result[2][0]*(h1_result[2][0].psd**0.5)).to_timeseries()\n",
    "whitened_strain_l1 = (l1_result[2][0]*(l1_result[2][0].psd**0.5)).to_timeseries()\n",
    "\n",
    "whitened_null_strain_h1 = (h1_null_result[2][0]*(h1_null_result[2][0].psd**0.5)).to_timeseries()\n",
    "whitened_null_strain_l1 = (l1_null_result[2][0]*(l1_null_result[2][0].psd**0.5)).to_timeseries()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the data used by the search\n",
    "\n",
    "We first plot the data used by the search. We offset the L1 data by the measured time of arrival difference, and multiply the Livingston strain by a factor of -1 to account for the relative orientations of the Hanford and Livingston detetectors. The GW150914 signal is clearly visible in the data. More high-frequency noise is visible here than in Figure 1, as only low-pass filter applied is the anti-aliasing filtered used to downsample the input data. This has a higher frequency cutoff than the Butterworth filter used to make Figure 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(whitened_strain_h1.sample_times-1126259462,whitened_strain_h1,label='H1',color='r')\n",
    "plt.plot(whitened_strain_l1.sample_times-1126259462+(t_h1-t_l1),-1.0*whitened_strain_l1,label='L1',color='g')\n",
    "\n",
    "plt.xlim([0.3,0.45])\n",
    "plt.ylim([-200,200])\n",
    "plt.legend(loc='best')\n",
    "plt.xlabel(\"Time from 1126259462 (seconds)\")\n",
    "plt.ylabel(\"Whitened strain\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the data with the waveform subtracted\n",
    "\n",
    "We now plot the time-series data created by ``pycbc_inspiral`` after the best-fit waveform has been subtracted. The GW150914 signal is no longer visible by eye."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(whitened_null_strain_h1.sample_times-1126259462,whitened_null_strain_h1,label='H1',color='r')\n",
    "plt.plot(whitened_null_strain_l1.sample_times-1126259462+(t_h1-t_l1),-1.0*whitened_null_strain_l1,label='L1',color='g')\n",
    "\n",
    "plt.xlim([0.3,0.45])\n",
    "plt.ylim([-200,200])\n",
    "plt.legend(loc='best')\n",
    "plt.xlabel(\"Time from 1126259462 (seconds)\")\n",
    "plt.ylabel(\"Whitened strain\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correllations in the residual data\n",
    "\n",
    "We now look numerically for correllations in the above strain data.\n",
    "\n",
    "### Set up the correllation function\n",
    "\n",
    "To compute the correllation of the residuals, we use the [code written by Creswell et al.](http://www.nbi.ku.dk/gravitational-waves/correlations.html). This code, when run on the data from the Figure 1 of the PRL, reproduces the green curve in the lower right plot in Figure 7 of Creswell et al.\n",
    "\n",
    "Here we run the code on the strain data used by the filtering code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cross_correllation(h1_res_times, h1_res_strain, l1_res_times, l1_res_strain):\n",
    "    \n",
    "    fs = 1./(h1_res_times[1]-h1_res_times[0])\n",
    "\n",
    "    t = 0.39\n",
    "    w = 0.04\n",
    "\n",
    "    min_indxt = np.where(abs(h1_res_times-t) == abs(h1_res_times-t).min())[0][0]\n",
    "    max_indxt = np.where(abs(h1_res_times-(t+w)) == abs(h1_res_times-(t+w)).min())[0][0]\n",
    "\n",
    "    deltatau = 0.01\n",
    "\n",
    "    tauind_min = int(-deltatau*fs); tauind_max = int(+deltatau*fs)\n",
    "    tauind = np.arange(tauind_min,tauind_max)\n",
    "    tau = tauind/fs\n",
    "\n",
    "    corr = []\n",
    "\n",
    "    for i in tauind:\n",
    "        corr.append(np.corrcoef(h1_res_strain[min_indxt+abs(tauind_min)+i:max_indxt-abs(tauind_max)+i],l1_res_strain[min_indxt+abs(tauind_min):max_indxt-abs(tauind_max)])[0][1])\n",
    "\n",
    "    corr = np.array(corr)\n",
    "    imax = np.argmax(abs(corr))\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(tau * 1000.,corr,'k',label=\"t=\"+str(t)+\", w=\"+str(w))\n",
    "    plt.axvline(1000*tau[imax], color='k')\n",
    "    plt.xlim(-10,10)\n",
    "    plt.xlabel(r\"$\\tau$ [ms]\")\n",
    "    plt.ylabel(r\"$C(t,\\tau,w)$\")\n",
    "    plt.ylim(-.9,.7)\n",
    "    plt.legend(loc='best')\n",
    "    \n",
    "    print('max |corr| = {:.2g} at tau = {:.3g} ms'.format(max(abs(corr)), 1000*tau[imax]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correllation of the input strain\n",
    "\n",
    "We first compute the cross correllation of the input strain data. A large peak can be seen at a time offset of 7.08 ms, corresponding to the GW150914 signal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_correllation(whitened_strain_h1.sample_times.numpy()-1126259462,whitened_strain_h1.numpy(),\n",
    "                     whitened_strain_l1.sample_times.numpy()-1126259462,whitened_strain_l1.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correllation of the waveform-subtracted strain\n",
    "\n",
    "Now we compute the cross correllation of the strain data that has had the best-fit waveform subtracted. The peak at 7.08 ms is no longer present and the maximum value of the correllation is now 0.26."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_correllation(whitened_null_strain_h1.sample_times.numpy()-1126259462,whitened_null_strain_h1.numpy(),\n",
    "                     whitened_null_strain_l1.sample_times.numpy()-1126259462,whitened_null_strain_l1.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Acknlowgements\n",
    "\n",
    "DAB thanks \n",
    "Jeandrew Brink,\n",
    "Jolien Creighton,\n",
    "Will Farr, \n",
    "Ben Farr, \n",
    "Jon Gair, \n",
    "Ian Harry,\n",
    "Daniel Holz, \n",
    "Andrew Jackson,\n",
    "Joey Key,\n",
    "Hao Liu,\n",
    "Andrew Lundgren,\n",
    "Jessica McIver, \n",
    "Pavel Naselsky, and\n",
    "Alexander Nitz\n",
    "for helpful discussions.\n",
    "This work is supported by National Science Foundation award PHY-1707954.\n",
    "DAB thanks the Niels Bohr Institute for its hospitality\n",
    "while part of this work was completed, \n",
    "the Kavli Foundation and the DNRF for supporting the 2017 Kavli Summer Program.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Appendix: Version information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.argv = ['pycbc_inspiral', '--version']\n",
    "try:\n",
    "    findchirp()\n",
    "except SystemExit:\n",
    "    pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
